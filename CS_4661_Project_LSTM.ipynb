{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-02-08</th>\n",
       "      <td>15.07</td>\n",
       "      <td>15.12</td>\n",
       "      <td>14.63</td>\n",
       "      <td>14.75</td>\n",
       "      <td>8407500</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-11</th>\n",
       "      <td>14.89</td>\n",
       "      <td>15.01</td>\n",
       "      <td>14.26</td>\n",
       "      <td>14.46</td>\n",
       "      <td>8882000</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-12</th>\n",
       "      <td>14.45</td>\n",
       "      <td>14.51</td>\n",
       "      <td>14.10</td>\n",
       "      <td>14.27</td>\n",
       "      <td>8126000</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-13</th>\n",
       "      <td>14.30</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.25</td>\n",
       "      <td>14.66</td>\n",
       "      <td>10259500</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-14</th>\n",
       "      <td>14.94</td>\n",
       "      <td>14.96</td>\n",
       "      <td>13.16</td>\n",
       "      <td>13.99</td>\n",
       "      <td>31879900</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>76.84</td>\n",
       "      <td>78.27</td>\n",
       "      <td>76.69</td>\n",
       "      <td>77.82</td>\n",
       "      <td>2982259</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-02</th>\n",
       "      <td>77.53</td>\n",
       "      <td>78.12</td>\n",
       "      <td>76.73</td>\n",
       "      <td>76.78</td>\n",
       "      <td>2595187</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>76.64</td>\n",
       "      <td>76.92</td>\n",
       "      <td>73.18</td>\n",
       "      <td>73.83</td>\n",
       "      <td>2962031</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-06</th>\n",
       "      <td>72.74</td>\n",
       "      <td>74.56</td>\n",
       "      <td>72.13</td>\n",
       "      <td>73.27</td>\n",
       "      <td>4924323</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-07</th>\n",
       "      <td>72.70</td>\n",
       "      <td>75.00</td>\n",
       "      <td>72.69</td>\n",
       "      <td>73.86</td>\n",
       "      <td>4534912</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>619040 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             open   high    low  close    volume Name\n",
       "dt                                                   \n",
       "2013-02-08  15.07  15.12  14.63  14.75   8407500  AAL\n",
       "2013-02-11  14.89  15.01  14.26  14.46   8882000  AAL\n",
       "2013-02-12  14.45  14.51  14.10  14.27   8126000  AAL\n",
       "2013-02-13  14.30  14.94  14.25  14.66  10259500  AAL\n",
       "2013-02-14  14.94  14.96  13.16  13.99  31879900  AAL\n",
       "...           ...    ...    ...    ...       ...  ...\n",
       "2018-02-01  76.84  78.27  76.69  77.82   2982259  ZTS\n",
       "2018-02-02  77.53  78.12  76.73  76.78   2595187  ZTS\n",
       "2018-02-05  76.64  76.92  73.18  73.83   2962031  ZTS\n",
       "2018-02-06  72.74  74.56  72.13  73.27   4924323  ZTS\n",
       "2018-02-07  72.70  75.00  72.69  73.86   4534912  ZTS\n",
       "\n",
       "[619040 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import necessary tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import scale\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read csv file, show data\n",
    "stock_df = pd.read_csv(\"https://raw.githubusercontent.com/LyJacky/stocks/4802f4e0f139ee0568afbad309086d90c78a53b7/all_stocks_5yr.csv\", parse_dates={'dt' : ['date']}, infer_datetime_format=True, \n",
    "                 low_memory=False, na_values=['nan','?'], index_col='dt')\n",
    "stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100_entry_avg</th>\n",
       "      <th>50_entry_avg</th>\n",
       "      <th>30_entry_avg</th>\n",
       "      <th>weekly_avg</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-02-08</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-11</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-12</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-13</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-14</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>53.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-02</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>52.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>49.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-06</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>51.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-07</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>51.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1259 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           100_entry_avg 50_entry_avg 30_entry_avg weekly_avg  close\n",
       "dt                                                                  \n",
       "2013-02-08                                                     14.75\n",
       "2013-02-11                                                     14.46\n",
       "2013-02-12                                                     14.27\n",
       "2013-02-13                                                     14.66\n",
       "2013-02-14                                                     13.99\n",
       "...                  ...          ...          ...        ...    ...\n",
       "2018-02-01                                                     53.88\n",
       "2018-02-02                                                     52.10\n",
       "2018-02-05                                                     49.76\n",
       "2018-02-06                                                     51.18\n",
       "2018-02-07                                                     51.40\n",
       "\n",
       "[1259 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove other stock data\n",
    "aal_df = stock_df[0:1259]\n",
    "\n",
    "# remove unused columns\n",
    "aal_df.pop(\"open\")\n",
    "aal_df.pop(\"low\")\n",
    "aal_df.pop(\"high\")\n",
    "aal_df.pop(\"volume\")\n",
    "aal_df.pop(\"Name\")\n",
    "\n",
    "# add past 100, 50, 30, weekly avg\n",
    "aal_df.insert(0, \"weekly_avg\", \" \")\n",
    "aal_df.insert(0, \"30_entry_avg\", \" \")\n",
    "aal_df.insert(0, \"50_entry_avg\", \" \")\n",
    "aal_df.insert(0, \"100_entry_avg\", \" \")\n",
    "\n",
    "# see result\n",
    "aal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100_entry_avg</th>\n",
       "      <th>50_entry_avg</th>\n",
       "      <th>30_entry_avg</th>\n",
       "      <th>weekly_avg</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-07-15</th>\n",
       "      <td>16.2605</td>\n",
       "      <td>17.2224</td>\n",
       "      <td>17.116</td>\n",
       "      <td>16.388571</td>\n",
       "      <td>17.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-16</th>\n",
       "      <td>16.2805</td>\n",
       "      <td>17.2314</td>\n",
       "      <td>17.076</td>\n",
       "      <td>16.477143</td>\n",
       "      <td>17.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-17</th>\n",
       "      <td>16.3043</td>\n",
       "      <td>17.2392</td>\n",
       "      <td>17.039667</td>\n",
       "      <td>16.531429</td>\n",
       "      <td>18.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-18</th>\n",
       "      <td>16.331</td>\n",
       "      <td>17.2536</td>\n",
       "      <td>16.998</td>\n",
       "      <td>16.641429</td>\n",
       "      <td>18.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-19</th>\n",
       "      <td>16.358</td>\n",
       "      <td>17.269</td>\n",
       "      <td>16.969667</td>\n",
       "      <td>16.791429</td>\n",
       "      <td>18.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>49.6466</td>\n",
       "      <td>51.1978</td>\n",
       "      <td>53.305667</td>\n",
       "      <td>57.932857</td>\n",
       "      <td>53.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-02</th>\n",
       "      <td>49.7839</td>\n",
       "      <td>51.4362</td>\n",
       "      <td>53.552667</td>\n",
       "      <td>58.2</td>\n",
       "      <td>52.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>49.8886</td>\n",
       "      <td>51.6166</td>\n",
       "      <td>53.678333</td>\n",
       "      <td>57.674286</td>\n",
       "      <td>49.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-06</th>\n",
       "      <td>49.9717</td>\n",
       "      <td>51.7612</td>\n",
       "      <td>53.736667</td>\n",
       "      <td>56.97</td>\n",
       "      <td>51.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-07</th>\n",
       "      <td>50.0493</td>\n",
       "      <td>51.9078</td>\n",
       "      <td>53.823333</td>\n",
       "      <td>56.242857</td>\n",
       "      <td>51.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1152 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           100_entry_avg 50_entry_avg 30_entry_avg weekly_avg  close\n",
       "dt                                                                  \n",
       "2013-07-15       16.2605      17.2224       17.116  16.388571  17.76\n",
       "2013-07-16       16.2805      17.2314       17.076  16.477143  17.95\n",
       "2013-07-17       16.3043      17.2392    17.039667  16.531429  18.45\n",
       "2013-07-18        16.331      17.2536       16.998  16.641429  18.42\n",
       "2013-07-19        16.358       17.269    16.969667  16.791429  18.23\n",
       "...                  ...          ...          ...        ...    ...\n",
       "2018-02-01       49.6466      51.1978    53.305667  57.932857  53.88\n",
       "2018-02-02       49.7839      51.4362    53.552667       58.2  52.10\n",
       "2018-02-05       49.8886      51.6166    53.678333  57.674286  49.76\n",
       "2018-02-06       49.9717      51.7612    53.736667      56.97  51.18\n",
       "2018-02-07       50.0493      51.9078    53.823333  56.242857  51.40\n",
       "\n",
       "[1152 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get rid of warnings\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# for loops to calculate avg for each column\n",
    "for x in range(14, 1259):\n",
    "    aal_df[\"weekly_avg\"][x] = aal_df[\"close\"][x-14:x-7].mean()\n",
    "\n",
    "for x in range(37, 1259):\n",
    "    aal_df[\"30_entry_avg\"][x] = aal_df[\"close\"][x-30-7:x-7].mean()\n",
    "\n",
    "for x in range(57, 1259):\n",
    "    aal_df[\"50_entry_avg\"][x] = aal_df[\"close\"][x-50-7:x-7].mean()\n",
    "\n",
    "for x in range(107, 1259):\n",
    "    aal_df[\"100_entry_avg\"][x] = aal_df[\"close\"][x-100-7:x-7].mean()\n",
    "\n",
    "# remove entries w/no data, see result\n",
    "aal_df = aal_df[107:1259]\n",
    "aal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.11.0\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.11.0-cp38-cp38-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.11.0\n",
      "  Using cached tensorflow_intel-2.11.0-cp38-cp38-win_amd64.whl (266.3 MB)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\bcanh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\bcanh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.12.1)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bcanh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\bcanh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.20.1)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.6-cp38-cp38-win_amd64.whl (896 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\bcanh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.10.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.28.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\bcanh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (20.9)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Using cached tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.1.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\bcanh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.4.3)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Using cached tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-22.11.23-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\bcanh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.15.0)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.51.1-cp38-cp38-win_amd64.whl (3.7 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\bcanh\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.36.2)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\bcanh\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\bcanh\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.0.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.14.1-py2.py3-none-any.whl (175 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-5.1.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\bcanh\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4.1)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\bcanh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bcanh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\bcanh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bcanh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2020.12.5)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\bcanh\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (2.4.7)\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, google-pasta, gast, flatbuffers, astunparse, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.0\n",
      "    Uninstalling importlib-metadata-3.10.0:\n",
      "      Successfully uninstalled importlib-metadata-3.10.0\n",
      "Successfully installed absl-py-1.3.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-22.11.23 gast-0.4.0 google-auth-2.14.1 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.1 importlib-metadata-5.1.0 libclang-14.0.6 markdown-3.4.1 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-intel-2.11.0 tensorflow-io-gcs-filesystem-0.28.0 termcolor-2.1.1\n"
     ]
    }
   ],
   "source": [
    "# install needed packages\n",
    "!pip install keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import additional tools\n",
    "import sys \n",
    "from scipy.stats import randint\n",
    "import seaborn as sns # used for plot interactive graph. \n",
    "from sklearn.model_selection import train_test_split # to split the data into two parts\n",
    "from sklearn.preprocessing import StandardScaler # for normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline # pipeline making\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics # for the check the error and accuracy of the model\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "\n",
    "## for Deep-learing:\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "import itertools\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdff = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(dff.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(dff.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)   var1(t)\n",
      "1   0.000000   0.000000   0.005338   0.012351   0.056109  0.000585\n",
      "2   0.000585   0.000259   0.004254   0.014443   0.060515  0.001281\n",
      "3   0.001281   0.000484   0.003270   0.015725   0.072108  0.002061\n",
      "4   0.002061   0.000900   0.002141   0.018324   0.071412  0.002851\n",
      "5   0.002851   0.001344   0.001373   0.021867   0.067007  0.003780\n"
     ]
    }
   ],
   "source": [
    "values = aal_df.values\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[6,7,8,9]], axis=1, inplace=True)\n",
    "print(reframed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(691, 1, 5) (691,) (460, 1, 5) (460,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "\n",
    "n_train_time = 691\n",
    "train = values[:n_train_time, :]\n",
    "test = values[n_train_time:, :]\n",
    "\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape) \n",
    "# Reshaped the input into the 3D format as expected by LSTMs, namely [samples, timesteps, features]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "14/14 - 3s - loss: 0.2715 - val_loss: 0.2679 - 3s/epoch - 249ms/step\n",
      "Epoch 2/40\n",
      "14/14 - 0s - loss: 0.1084 - val_loss: 0.0875 - 100ms/epoch - 7ms/step\n",
      "Epoch 3/40\n",
      "14/14 - 0s - loss: 0.0278 - val_loss: 0.0132 - 93ms/epoch - 7ms/step\n",
      "Epoch 4/40\n",
      "14/14 - 0s - loss: 0.0130 - val_loss: 0.0044 - 100ms/epoch - 7ms/step\n",
      "Epoch 5/40\n",
      "14/14 - 0s - loss: 0.0171 - val_loss: 0.0043 - 114ms/epoch - 8ms/step\n",
      "Epoch 6/40\n",
      "14/14 - 0s - loss: 0.0164 - val_loss: 0.0045 - 121ms/epoch - 9ms/step\n",
      "Epoch 7/40\n",
      "14/14 - 0s - loss: 0.0147 - val_loss: 0.0045 - 127ms/epoch - 9ms/step\n",
      "Epoch 8/40\n",
      "14/14 - 0s - loss: 0.0137 - val_loss: 0.0044 - 111ms/epoch - 8ms/step\n",
      "Epoch 9/40\n",
      "14/14 - 0s - loss: 0.0129 - val_loss: 0.0043 - 108ms/epoch - 8ms/step\n",
      "Epoch 10/40\n",
      "14/14 - 0s - loss: 0.0123 - val_loss: 0.0043 - 95ms/epoch - 7ms/step\n",
      "Epoch 11/40\n",
      "14/14 - 0s - loss: 0.0116 - val_loss: 0.0041 - 94ms/epoch - 7ms/step\n",
      "Epoch 12/40\n",
      "14/14 - 0s - loss: 0.0117 - val_loss: 0.0040 - 95ms/epoch - 7ms/step\n",
      "Epoch 13/40\n",
      "14/14 - 0s - loss: 0.0108 - val_loss: 0.0039 - 97ms/epoch - 7ms/step\n",
      "Epoch 14/40\n",
      "14/14 - 0s - loss: 0.0103 - val_loss: 0.0040 - 100ms/epoch - 7ms/step\n",
      "Epoch 15/40\n",
      "14/14 - 0s - loss: 0.0103 - val_loss: 0.0039 - 104ms/epoch - 7ms/step\n",
      "Epoch 16/40\n",
      "14/14 - 0s - loss: 0.0095 - val_loss: 0.0038 - 99ms/epoch - 7ms/step\n",
      "Epoch 17/40\n",
      "14/14 - 0s - loss: 0.0095 - val_loss: 0.0038 - 169ms/epoch - 12ms/step\n",
      "Epoch 18/40\n",
      "14/14 - 0s - loss: 0.0084 - val_loss: 0.0038 - 138ms/epoch - 10ms/step\n",
      "Epoch 19/40\n",
      "14/14 - 0s - loss: 0.0083 - val_loss: 0.0038 - 131ms/epoch - 9ms/step\n",
      "Epoch 20/40\n",
      "14/14 - 0s - loss: 0.0083 - val_loss: 0.0038 - 137ms/epoch - 10ms/step\n",
      "Epoch 21/40\n",
      "14/14 - 0s - loss: 0.0080 - val_loss: 0.0038 - 129ms/epoch - 9ms/step\n",
      "Epoch 22/40\n",
      "14/14 - 0s - loss: 0.0079 - val_loss: 0.0037 - 152ms/epoch - 11ms/step\n",
      "Epoch 23/40\n",
      "14/14 - 0s - loss: 0.0071 - val_loss: 0.0037 - 189ms/epoch - 14ms/step\n",
      "Epoch 24/40\n",
      "14/14 - 0s - loss: 0.0066 - val_loss: 0.0037 - 197ms/epoch - 14ms/step\n",
      "Epoch 25/40\n",
      "14/14 - 0s - loss: 0.0066 - val_loss: 0.0037 - 190ms/epoch - 14ms/step\n",
      "Epoch 26/40\n",
      "14/14 - 0s - loss: 0.0068 - val_loss: 0.0037 - 172ms/epoch - 12ms/step\n",
      "Epoch 27/40\n",
      "14/14 - 0s - loss: 0.0068 - val_loss: 0.0036 - 164ms/epoch - 12ms/step\n",
      "Epoch 28/40\n",
      "14/14 - 0s - loss: 0.0059 - val_loss: 0.0036 - 137ms/epoch - 10ms/step\n",
      "Epoch 29/40\n",
      "14/14 - 0s - loss: 0.0063 - val_loss: 0.0036 - 141ms/epoch - 10ms/step\n",
      "Epoch 30/40\n",
      "14/14 - 0s - loss: 0.0061 - val_loss: 0.0035 - 149ms/epoch - 11ms/step\n",
      "Epoch 31/40\n",
      "14/14 - 0s - loss: 0.0055 - val_loss: 0.0035 - 130ms/epoch - 9ms/step\n",
      "Epoch 32/40\n",
      "14/14 - 0s - loss: 0.0058 - val_loss: 0.0035 - 106ms/epoch - 8ms/step\n",
      "Epoch 33/40\n",
      "14/14 - 0s - loss: 0.0053 - val_loss: 0.0034 - 109ms/epoch - 8ms/step\n",
      "Epoch 34/40\n",
      "14/14 - 0s - loss: 0.0056 - val_loss: 0.0034 - 103ms/epoch - 7ms/step\n",
      "Epoch 35/40\n",
      "14/14 - 0s - loss: 0.0055 - val_loss: 0.0033 - 107ms/epoch - 8ms/step\n",
      "Epoch 36/40\n",
      "14/14 - 0s - loss: 0.0047 - val_loss: 0.0033 - 121ms/epoch - 9ms/step\n",
      "Epoch 37/40\n",
      "14/14 - 0s - loss: 0.0053 - val_loss: 0.0032 - 131ms/epoch - 9ms/step\n",
      "Epoch 38/40\n",
      "14/14 - 0s - loss: 0.0045 - val_loss: 0.0032 - 152ms/epoch - 11ms/step\n",
      "Epoch 39/40\n",
      "14/14 - 0s - loss: 0.0048 - val_loss: 0.0031 - 109ms/epoch - 8ms/step\n",
      "Epoch 40/40\n",
      "14/14 - 0s - loss: 0.0050 - val_loss: 0.0030 - 98ms/epoch - 7ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 2ms/step\n",
      "Test RMSE: 1.882\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=40, batch_size=50, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], 5))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat, test_X[:, -4:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, -4:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19b14f37c7b44b97eef715882cef8379e38e4d5c393794f4cd55caff931c4cae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
